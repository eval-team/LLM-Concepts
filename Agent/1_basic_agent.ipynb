{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab1fb05",
   "metadata": {},
   "source": [
    "# Basic Agent with langchain\n",
    "\n",
    "\n",
    "* Conversational Agent with Context Awareness\n",
    "* Question Answering Agent\n",
    "* Data Analysis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f364cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -q langchain langchain_experimental openai python-dotenv langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726d5d8",
   "metadata": {},
   "source": [
    "## Conversational Agent with Context Awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9356763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now get the API key (it should be loaded from .env file)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "else:\n",
    "    print(\"Warning: OPENAI_API_KEY not found in environment variables.\")\n",
    "    print(\"Please make sure you have a .env file with OPENAI_API_KEY=your_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ea36a",
   "metadata": {},
   "source": [
    "### Initialize language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc76f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c0bb8",
   "metadata": {},
   "source": [
    "### in-memory store for chat histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b39d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072d68c",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d60a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd945be",
   "metadata": {},
   "source": [
    "### Combine the prompt and model into a runnable chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b8cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481872ec",
   "metadata": {},
   "source": [
    "### Wrap the chain with message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce07cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc33115",
   "metadata": {},
   "source": [
    "### Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce84ac2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "AI: Your previous message was, \"Hello! How are you?\" How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_123\"\n",
    "\n",
    "\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hello! How are you?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response1.content)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What was my previous message?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcca8a",
   "metadata": {},
   "source": [
    "### Print the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88d1b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation History:\n",
      "human: Hello! How are you?\n",
      "ai: Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "human: What was my previous message?\n",
      "ai: Your previous message was, \"Hello! How are you?\" How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConversation History:\")\n",
    "for message in store[session_id].messages:\n",
    "    print(f\"{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb849d6",
   "metadata": {},
   "source": [
    "## Question Answering Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e2813",
   "metadata": {},
   "source": [
    "We will use the same model and but prompt template inste of ChatPromptTemplate.\n",
    "\n",
    "* For completion-style LLMs. we can use prompt template with placeholders, and fill them in at runtime.\n",
    "\n",
    "* For chat-based LLMs, we use ChatPromptTemplate with messages. Consists of a sequence of messages (SystemMessage, HumanMessage, AIMessage, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92bd4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4fcb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful AI assistant. Your task is to answer the user's question to the best of your ability.\n",
    "\n",
    "User's question: {question}\n",
    "\n",
    "Please provide a clear and concise answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd7049cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8992333",
   "metadata": {},
   "source": [
    "##### Define the get_answer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a701676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question):\n",
    "    \"\"\"\n",
    "    Get an answer to the given question using the QA chain.\n",
    "    \"\"\"\n",
    "    input_variables = {\"question\": question}\n",
    "    response = qa_chain.invoke(input_variables).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a0ca6",
   "metadata": {},
   "source": [
    "##### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e40a258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of France?\n",
      "Answer: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "answer = get_answer(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5aef16",
   "metadata": {},
   "source": [
    "## Data Analysis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba678b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "712d8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents import AgentType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d5e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate sample data\n",
    "# n_rows = 1000\n",
    "\n",
    "# # Generate dates\n",
    "# start_date = datetime(2022, 1, 1)\n",
    "# dates = [start_date + timedelta(days=i) for i in range(n_rows)]\n",
    "\n",
    "# # Define data categories\n",
    "# makes = ['Toyota', 'Honda', 'Ford', 'Chevrolet', 'Nissan', 'BMW', 'Mercedes', 'Audi', 'Hyundai', 'Kia']\n",
    "# models = ['Sedan', 'SUV', 'Truck', 'Hatchback', 'Coupe', 'Van']\n",
    "# colors = ['Red', 'Blue', 'Black', 'White', 'Silver', 'Gray', 'Green']\n",
    "\n",
    "# # Create the dataset\n",
    "# data = {\n",
    "#     'Date': dates,\n",
    "#     'Make': np.random.choice(makes, n_rows),\n",
    "#     'Model': np.random.choice(models, n_rows),\n",
    "#     'Color': np.random.choice(colors, n_rows),\n",
    "#     'Year': np.random.randint(2015, 2023, n_rows),\n",
    "#     'Price': np.random.uniform(20000, 80000, n_rows).round(2),\n",
    "#     'Mileage': np.random.uniform(0, 100000, n_rows).round(0),\n",
    "#     'EngineSize': np.random.choice([1.6, 2.0, 2.5, 3.0, 3.5, 4.0], n_rows),\n",
    "#     'FuelEfficiency': np.random.uniform(20, 40, n_rows).round(1),\n",
    "#     'SalesPerson': np.random.choice(['Alice', 'Bob', 'Charlie', 'David', 'Eva'], n_rows)\n",
    "# }\n",
    "\n",
    "# # Create DataFrame and sort by date\n",
    "# df = pd.DataFrame(data).sort_values('Date')\n",
    "\n",
    "# # Save to CSV file\n",
    "# csv_filename = \"car_sales_data.csv\"\n",
    "# df.to_csv(csv_filename, index=False)\n",
    "# print(f\"Data saved to {csv_filename}\")\n",
    "\n",
    "# # Display sample data and statistics\n",
    "# print(\"\\nFirst few rows of the generated data:\")\n",
    "# print(df.head())\n",
    "\n",
    "# print(\"\\nDataFrame info:\")\n",
    "# df.info()\n",
    "\n",
    "# print(\"\\nSummary statistics:\")\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db451e5f",
   "metadata": {},
   "source": [
    "### Load data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "febf1a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (1000, 10)\n",
      "\n",
      "First few rows of loaded data:\n",
      "        Date      Make      Model   Color  Year     Price  Mileage  \\\n",
      "0 2022-01-01  Mercedes      Sedan    Blue  2020  43639.25  65879.0   \n",
      "1 2022-01-02    Toyota  Hatchback    Gray  2016  44983.53  62313.0   \n",
      "2 2022-01-03   Hyundai        Van     Red  2019  47054.44  49459.0   \n",
      "3 2022-01-04    Toyota      Sedan    Blue  2020  69614.21  21126.0   \n",
      "4 2022-01-05    Nissan      Coupe  Silver  2018  25880.32  38198.0   \n",
      "\n",
      "   EngineSize  FuelEfficiency SalesPerson  \n",
      "0         1.6            26.6       David  \n",
      "1         3.5            23.4         Eva  \n",
      "2         2.5            29.3         Bob  \n",
      "3         3.0            22.0         Bob  \n",
      "4         4.0            26.7         Bob  \n",
      "\n",
      "Data types:\n",
      "Date              datetime64[ns]\n",
      "Make                      object\n",
      "Model                     object\n",
      "Color                     object\n",
      "Year                       int64\n",
      "Price                    float64\n",
      "Mileage                  float64\n",
      "EngineSize               float64\n",
      "FuelEfficiency           float64\n",
      "SalesPerson               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('car_sales_data.csv')\n",
    "\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "\n",
    "print(\"\\nFirst few rows of loaded data:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7044d",
   "metadata": {},
   "source": [
    "##### Create Data Analysis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d3cfaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analysis Agent is ready. You can now ask questions about the data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    ChatOpenAI(model=\"gpt-4o\", temperature=0),\n",
    "    df,\n",
    "    verbose=True,\n",
    "    allow_dangerous_code=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    ")\n",
    "print(\"Data Analysis Agent is ready. You can now ask questions about the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e4ea668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_agent(question):\n",
    "    \"\"\"Function to ask questions to the agent and display the response\"\"\"\n",
    "    response = agent.run({\n",
    "        \"input\": question,\n",
    "        \"agent_scratchpad\": f\"Human: {question}\\nAI: To answer this question, I need to use Python to analyze the dataframe. I'll use the python_repl_ast tool.\\n\\nAction: python_repl_ast\\nAction Input: \",\n",
    "    })\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {response}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c667448",
   "metadata": {},
   "source": [
    "Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55fa50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiu User\\AppData\\Local\\Temp\\ipykernel_41756\\610968568.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent.run({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'df.columns.tolist()'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Date', 'Make', 'Model', 'Color', 'Year', 'Price', 'Mileage', 'EngineSize', 'FuelEfficiency', 'SalesPerson']\u001b[0m\u001b[32;1m\u001b[1;3mThe column names in the dataset are:\n",
      "\n",
      "1. Date\n",
      "2. Make\n",
      "3. Model\n",
      "4. Color\n",
      "5. Year\n",
      "6. Price\n",
      "7. Mileage\n",
      "8. EngineSize\n",
      "9. FuelEfficiency\n",
      "10. SalesPerson\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Question: What are the column names in this dataset?\n",
      "Answer: The column names in the dataset are:\n",
      "\n",
      "1. Date\n",
      "2. Make\n",
      "3. Model\n",
      "4. Color\n",
      "5. Year\n",
      "6. Price\n",
      "7. Mileage\n",
      "8. EngineSize\n",
      "9. FuelEfficiency\n",
      "10. SalesPerson\n",
      "---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'len(df)'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1000\u001b[0m\u001b[32;1m\u001b[1;3mThe dataset contains 1,000 rows.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Question: How many rows are in this dataset?\n",
      "Answer: The dataset contains 1,000 rows.\n",
      "---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"average_price = df['Price'].mean()\\naverage_price\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m50557.660659999994\u001b[0m\u001b[32;1m\u001b[1;3mThe average price of cars sold is approximately $50,557.66.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Question: What is the average price of cars sold?\n",
      "Answer: The average price of cars sold is approximately $50,557.66.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "ask_agent(\"What are the column names in this dataset?\")\n",
    "ask_agent(\"How many rows are in this dataset?\")\n",
    "ask_agent(\"What is the average price of cars sold?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
