{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f685e6d",
   "metadata": {},
   "source": [
    "# Contract Analysis Assistant\n",
    "\n",
    "This is an AI-powered system for contract analysis, generating insights and professional reports with minimal manual intervention.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "1. **Input Selection**:\n",
    "   - Users upload contracts and supporting documents or integrate external legal APIs.\n",
    "\n",
    "2. **AI Planning**:\n",
    "   - A team of AI analysts is generated, each specializing in a specific domain (e.g., compliance, finance, operations).\n",
    "   - `Human-in-the-loop` refines focus areas.\n",
    "\n",
    "3. **AI Research**:\n",
    "   - Analysts engage in multi-turn conversations with domain-specific AI experts.\n",
    "   - Discussions cover strengths, weaknesses, risks, and improvements in the contract.\n",
    "\n",
    "4. **Parallel Processing**:\n",
    "   - Researches and data extraction run simultaneously using `map-reduce` for speed and scalability.\n",
    "\n",
    "5. **Customizable Reports**:\n",
    "   - Insights are synthesized into professional reports tailored to user needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U langgraph langchain-community langchain-openai docx pinecone[grpc] ipywidgets PyPDF2 python-docx install langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae0db84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "import json\n",
    "import os\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, List, Optional, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, MessagesState, START, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "import operator\n",
    "import getpass\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now get the API key (it should be loaded from .env file)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "# Set the OPENAI_API_KEY environment variable if it's found\n",
    "if openai_api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "else:\n",
    "    print(\"Warning: OPENAI_API_KEY not found in environment variables.\")\n",
    "    print(\"Please make sure you have a .env file with OPENAI_API_KEY=your_api_key\")\n",
    "\n",
    "# Initialize Pinecone with GRPC client\n",
    "if(pinecone_api_key):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
    "else:\n",
    "    print(\"Warning: PINECONE_API_KEY not found in environment variables.\")\n",
    "    print(\"Please make sure you have a .env file with PINECONE_API_KEY=your_api_key\")\n",
    "\n",
    "# Initialize Langchain API key\n",
    "if(langchain_api_key):\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\"\n",
    "else:\n",
    "    print(\"Warning: LANGCHAIN_API_KEY not found in environment variables.\")\n",
    "    print(\"Please make sure you have a .env file with LANGCHAIN_API_KEY=your_api_key\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e629ed",
   "metadata": {},
   "source": [
    "## Clause Analysis Component Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51286458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone as PineconeClient\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "class ClauseMetadata(BaseModel):\n",
    "    jurisdiction: str\n",
    "    version: str\n",
    "    last_updated: str\n",
    "\n",
    "\n",
    "class ClauseRetriever:\n",
    "    def __init__(self, json_file_path: Optional[str] = None):\n",
    "        # Initialize Pinecone client\n",
    "        self.pc = PineconeClient(api_key=pinecone_api_key)\n",
    "\n",
    "        self.index_name = \"contract-clauses\"\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        # Get index instance\n",
    "        self.index = self.pc.Index(self.index_name)\n",
    "\n",
    "        # Initialize vector store\n",
    "        self.vectorstore = PineconeVectorStore(\n",
    "            index=self.index,\n",
    "            embedding=self.embeddings,\n",
    "            text_key=\"text\"\n",
    "        )\n",
    "\n",
    "        # Only load and index clauses if json_file_path is provided\n",
    "        if json_file_path:\n",
    "            self._load_clauses(json_file_path)\n",
    "\n",
    "    def _load_clauses(self, json_file_path: str):\n",
    "        \"\"\"Load and index clauses from JSON file\"\"\"\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            self.contract_types = json.load(file)\n",
    "\n",
    "        # Process each contract type and its clauses\n",
    "        for contract_data in self.contract_types:\n",
    "            self._index_contract_clauses(contract_data)\n",
    "\n",
    "    def _index_contract_clauses(self, contract_data: Dict):\n",
    "        \"\"\"Index clauses for a specific contract type\"\"\"\n",
    "        contract_type = contract_data[\"contract_type\"]\n",
    "\n",
    "        vectors_to_upsert = []\n",
    "        for clause in contract_data[\"clauses\"]:\n",
    "            # Create the text to be embedded\n",
    "            clause_text = f\"\"\"\n",
    "            Contract Type: {contract_type}\n",
    "            Clause Title: {clause['clause_title']}\n",
    "\n",
    "            {clause['clause_text']}\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            # Create metadata\n",
    "            metadata = {\n",
    "                \"contract_type\": contract_type,\n",
    "                \"clause_title\": clause[\"clause_title\"],\n",
    "                \"jurisdiction\": clause[\"metadata\"][\"jurisdiction\"],\n",
    "                \"version\": clause[\"metadata\"][\"version\"],\n",
    "                \"last_updated\": clause[\"metadata\"][\"last_updated\"],\n",
    "                \"text\": clause_text\n",
    "            }\n",
    "\n",
    "            # Get vector embedding\n",
    "            vector = self.embeddings.embed_query(clause_text)\n",
    "\n",
    "            # Add to upsert batch\n",
    "            vectors_to_upsert.append({\n",
    "                \"id\": f\"{contract_type}-{clause['clause_title']}\".lower().replace(\" \", \"-\"),\n",
    "                \"values\": vector,\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "\n",
    "            # Batch upsert in chunks of 100\n",
    "            if len(vectors_to_upsert) >= 100:\n",
    "                self.index.upsert(vectors=vectors_to_upsert)\n",
    "                vectors_to_upsert = []\n",
    "\n",
    "        # Upsert any remaining vectors\n",
    "        if vectors_to_upsert:\n",
    "            self.index.upsert(vectors=vectors_to_upsert)\n",
    "\n",
    "    def get_clauses_by_contract_type(self,\n",
    "                                    contract_type: str,\n",
    "                                    jurisdiction: Optional[str] = None,\n",
    "                                    k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Retrieve relevant clauses based on contract type and optional filters\"\"\"\n",
    "        # Build filter dict\n",
    "        filter_dict = {\"contract_type\": contract_type}\n",
    "        if jurisdiction:\n",
    "            filter_dict[\"jurisdiction\"] = jurisdiction\n",
    "\n",
    "        # Create query vector\n",
    "        query_text = f\"Find clauses for {contract_type} contract\"\n",
    "        query_vector = self.embeddings.embed_query(query_text)\n",
    "\n",
    "        # Search for relevant clauses\n",
    "        results = self.index.query(\n",
    "            vector=query_vector,\n",
    "            top_k=k,\n",
    "            filter=filter_dict,\n",
    "            include_values=True,\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        # Format results\n",
    "        formatted_results = []\n",
    "        for match in results['matches']:\n",
    "            formatted_results.append({\n",
    "                \"clause_title\": match['metadata'][\"clause_title\"],\n",
    "                \"clause_text\": match['metadata'][\"text\"],\n",
    "                \"metadata\": match['metadata'],\n",
    "                \"relevance_score\": match['score']\n",
    "            })\n",
    "\n",
    "        return formatted_results\n",
    "\n",
    "    def search_clauses(self,\n",
    "                        query: str,\n",
    "                        contract_type: Optional[str] = None,\n",
    "                        jurisdiction: Optional[str] = None,\n",
    "                        k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search for clauses based on semantic similarity\"\"\"\n",
    "        # Build filter dict\n",
    "        filter_dict = {}\n",
    "        if contract_type:\n",
    "            filter_dict[\"contract_type\"] = contract_type\n",
    "        if jurisdiction:\n",
    "            filter_dict[\"jurisdiction\"] = jurisdiction\n",
    "\n",
    "        # Create query vector\n",
    "        query_vector = self.embeddings.embed_query(query)\n",
    "\n",
    "        # Perform search\n",
    "        results = self.index.query(\n",
    "            vector=query_vector,\n",
    "            top_k=k,\n",
    "            filter=filter_dict if filter_dict else None,\n",
    "            include_values=True,\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        # Format results\n",
    "        formatted_results = []\n",
    "        for match in results['matches']:\n",
    "            formatted_results.append({\n",
    "                \"clause_title\": match['metadata'][\"clause_title\"],\n",
    "                \"clause_text\": match['metadata'][\"text\"],\n",
    "                \"metadata\": match['metadata'],\n",
    "                \"relevance_score\": match['score']\n",
    "            })\n",
    "\n",
    "        return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df20a14",
   "metadata": {},
   "source": [
    "## Load clauses.json to pinecone, it should be in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9177ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_retriever = ClauseRetriever(\"test-data/clauses.json\")\n",
    "employment_clauses = clause_retriever.get_clauses_by_contract_type(\n",
    "        contract_type=\"Employment Contract\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd573cf9",
   "metadata": {},
   "source": [
    "## Contract Review State and Supporting Models\n",
    "\n",
    "This section defines the core data structures used for managing the state of a contract review process, detailing the contract type, review steps, modifications, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd371b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c9119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
